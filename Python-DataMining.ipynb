{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.3 (default, Jul  2 2020, 11:26:31) \n",
      "[Clang 10.0.0 ]\n",
      "scipy: 1.5.0\n",
      "numpy: 1.18.5\n",
      "matplotlib: 3.2.2\n",
      "pandas: 1.0.5\n",
      "sklearn: 0.23.1\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "# Load libraries\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal-length  sepal-width  petal-length  petal-width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# head\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class distribution\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.941667 (0.065085)\n",
      "LDA: 0.975000 (0.038188)\n",
      "KNN: 0.958333 (0.041667)\n",
      "CART: 0.950000 (0.055277)\n",
      "NB: 0.950000 (0.055277)\n",
      "SVM: 0.983333 (0.033333)\n"
     ]
    }
   ],
   "source": [
    "...\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset knn\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00         6\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions for knn model\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset decision tree\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  6]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      0.92      0.96        13\n",
      " Iris-virginica       0.86      1.00      0.92         6\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.95      0.97      0.96        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions for knn model\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(167.4, 199.32, 'X[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
       " Text(141.64615384615385, 163.07999999999998, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
       " Text(193.15384615384616, 163.07999999999998, 'X[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
       " Text(103.01538461538462, 126.83999999999999, 'X[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
       " Text(51.50769230769231, 90.6, 'X[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
       " Text(25.753846153846155, 54.359999999999985, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
       " Text(77.26153846153846, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(154.52307692307693, 90.6, 'X[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(128.76923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(180.27692307692308, 54.359999999999985, 'X[0] <= 6.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(154.52307692307693, 18.119999999999976, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(206.03076923076924, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(283.2923076923077, 126.83999999999999, 'X[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
       " Text(257.53846153846155, 90.6, 'X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(231.7846153846154, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(283.2923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(309.04615384615386, 90.6, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    ">>> clf = tree.DecisionTreeClassifier()\n",
    ">>> clf = clf.fit(X, y)\n",
    "tree.plot_tree(clf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length  sepal-width  petal-length  petal-width           class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length  sepal-width  petal-length  petal-width           class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get new dataset that will be cleaned\n",
    "cleaned_dataset = dataset\n",
    "print(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast every attributes to str\n",
    "\n",
    "cleaned_dataset=cleaned_dataset.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning functions\n",
    "\n",
    "def sepal_length_adapter(df,attribute):\n",
    "    for i in range(len(df)): \n",
    "        if float(df[attribute][i])<=5.1 :\n",
    "            df.at[i,attribute] = \"sm_sl\"\n",
    "        elif float(df[attribute][i])<=6.4 :\n",
    "            df.at[i,attribute] = \"m_sl\"\n",
    "        else:\n",
    "            df.at[i,attribute] = \"lg_sl\"\n",
    "            \n",
    "def sepal_width_adapter(df,attribute):\n",
    "    for i in range(len(df)): \n",
    "        if float(df[attribute][i])<=2.8 :\n",
    "            df.at[i,attribute] = \"sm_sw\"\n",
    "        elif float(df[attribute][i])<=3.3 :\n",
    "            df.at[i,attribute] = \"m_sw\"\n",
    "        else:\n",
    "            df.at[i,attribute] = \"lg_sw\"\n",
    "\n",
    "def petal_length_adapter(df,attribute):\n",
    "    for i in range(len(df)): \n",
    "        if float(df[attribute][i])<=1.6 :\n",
    "            df.at[i,attribute] = \"sm_pl\"\n",
    "        elif float(df[attribute][i])<=5.1 :\n",
    "            df.at[i,attribute] = \"m_pl\"\n",
    "        else:\n",
    "            df.at[i,attribute] = \"lg_pl\"\n",
    "            \n",
    "def petal_width_adapter(df,attribute):\n",
    "    for i in range(len(df)): \n",
    "        if float(df[attribute][i])<=0.3 :\n",
    "            df.at[i,attribute] = \"sm_pw\"\n",
    "        elif float(df[attribute][i])<=1.8 :\n",
    "            df.at[i,attribute] = \"m_pw\"\n",
    "        else:\n",
    "            df.at[i,attribute] = \"lg_pw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "\n",
    "sepal_length_adapter(cleaned_dataset,\"sepal-length\")\n",
    "sepal_width_adapter(cleaned_dataset,\"sepal-width\")\n",
    "petal_length_adapter(cleaned_dataset,\"petal-length\")\n",
    "petal_width_adapter(cleaned_dataset,\"petal-width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal-length sepal-width petal-length petal-width           class\n",
      "0          sm_sl       lg_sw        sm_pl       sm_pw     Iris-setosa\n",
      "1          sm_sl        m_sw        sm_pl       sm_pw     Iris-setosa\n",
      "2          sm_sl        m_sw        sm_pl       sm_pw     Iris-setosa\n",
      "3          sm_sl        m_sw        sm_pl       sm_pw     Iris-setosa\n",
      "4          sm_sl       lg_sw        sm_pl       sm_pw     Iris-setosa\n",
      "..           ...         ...          ...         ...             ...\n",
      "145        lg_sl        m_sw        lg_pl       lg_pw  Iris-virginica\n",
      "146         m_sl       sm_sw         m_pl       lg_pw  Iris-virginica\n",
      "147        lg_sl        m_sw        lg_pl       lg_pw  Iris-virginica\n",
      "148         m_sl       lg_sw        lg_pl       lg_pw  Iris-virginica\n",
      "149         m_sl        m_sw         m_pl        m_pw  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = cleaned_dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## association rules\n",
    "\n",
    "# Formatting data correctly:\n",
    "\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(array.shape[0]):\n",
    "    d = []\n",
    "    for j in range(array.shape[1]):\n",
    "        d.append(array[i,j])\n",
    "    data.append(d)\n",
    "    \n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(data).transform(data)\n",
    "df = pandas.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "      <th>lg_pl</th>\n",
       "      <th>lg_pw</th>\n",
       "      <th>lg_sl</th>\n",
       "      <th>lg_sw</th>\n",
       "      <th>m_pl</th>\n",
       "      <th>m_pw</th>\n",
       "      <th>m_sl</th>\n",
       "      <th>m_sw</th>\n",
       "      <th>sm_pl</th>\n",
       "      <th>sm_pw</th>\n",
       "      <th>sm_sl</th>\n",
       "      <th>sm_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica  lg_pl  lg_pw  lg_sl  lg_sw  \\\n",
       "0           True            False           False  False  False  False   True   \n",
       "1           True            False           False  False  False  False  False   \n",
       "2           True            False           False  False  False  False  False   \n",
       "3           True            False           False  False  False  False  False   \n",
       "4           True            False           False  False  False  False   True   \n",
       "..           ...              ...             ...    ...    ...    ...    ...   \n",
       "145        False            False            True   True   True   True  False   \n",
       "146        False            False            True  False   True  False  False   \n",
       "147        False            False            True   True   True   True  False   \n",
       "148        False            False            True   True   True  False   True   \n",
       "149        False            False            True  False  False  False  False   \n",
       "\n",
       "      m_pl   m_pw   m_sl   m_sw  sm_pl  sm_pw  sm_sl  sm_sw  \n",
       "0    False  False  False  False   True   True   True  False  \n",
       "1    False  False  False   True   True   True   True  False  \n",
       "2    False  False  False   True   True   True   True  False  \n",
       "3    False  False  False   True   True   True   True  False  \n",
       "4    False  False  False  False   True   True   True  False  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "145  False  False  False   True  False  False  False  False  \n",
       "146   True  False   True  False  False  False  False   True  \n",
       "147  False  False  False   True  False  False  False  False  \n",
       "148  False  False   True  False  False  False  False  False  \n",
       "149   True   True   True   True  False  False  False  False  \n",
       "\n",
       "[150 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.226667</td>\n",
       "      <td>(lg_pl)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.226667</td>\n",
       "      <td>(lg_pw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>(m_sl, m_pl, sm_sw, m_pw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>(sm_pl, m_sw, sm_pw, sm_sl)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>(m_sw, sm_sl, Iris-setosa, sm_pl, sm_pw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>(m_sw, m_pw, Iris-versicolor, m_sl, m_pl)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>(m_pw, Iris-versicolor, m_sl, m_pl, sm_sw)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support                                    itemsets\n",
       "0    0.333333                               (Iris-setosa)\n",
       "1    0.333333                           (Iris-versicolor)\n",
       "2    0.333333                            (Iris-virginica)\n",
       "3    0.226667                                     (lg_pl)\n",
       "4    0.226667                                     (lg_pw)\n",
       "..        ...                                         ...\n",
       "115  0.166667                   (m_sl, m_pl, sm_sw, m_pw)\n",
       "116  0.120000                 (sm_pl, m_sw, sm_pw, sm_sl)\n",
       "117  0.120000    (m_sw, sm_sl, Iris-setosa, sm_pl, sm_pw)\n",
       "118  0.100000   (m_sw, m_pw, Iris-versicolor, m_sl, m_pl)\n",
       "119  0.140000  (m_pw, Iris-versicolor, m_sl, m_pl, sm_sw)\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we return the items and itemsets with at least 20% support\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "output = apriori(df, min_support=0.1, use_colnames=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(output, metric=\"lift\", min_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>(m_pl, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>2.459016</td>\n",
       "      <td>0.197778</td>\n",
       "      <td>3.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>(m_sl, m_pl, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>(m_pl, m_sw, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>2.538462</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>(m_pl, sm_sw, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>2.531250</td>\n",
       "      <td>0.108889</td>\n",
       "      <td>4.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>(m_sl, m_pl, m_sw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>(m_sl, sm_sw, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>3.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>(m_sl, m_pl, m_sw, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>(m_sl, m_pl, sm_sw, m_pw)</td>\n",
       "      <td>(Iris-versicolor)</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>0.084444</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   antecedents        consequents  antecedent support  \\\n",
       "114               (m_pl, m_pw)  (Iris-versicolor)            0.406667   \n",
       "358         (m_sl, m_pl, m_pw)  (Iris-versicolor)            0.300000   \n",
       "372         (m_pl, m_sw, m_pw)  (Iris-versicolor)            0.173333   \n",
       "384        (m_pl, sm_sw, m_pw)  (Iris-versicolor)            0.213333   \n",
       "398         (m_sl, m_pl, m_sw)  (Iris-versicolor)            0.120000   \n",
       "436        (m_sl, sm_sw, m_pw)  (Iris-versicolor)            0.173333   \n",
       "578   (m_sl, m_pl, m_sw, m_pw)  (Iris-versicolor)            0.120000   \n",
       "607  (m_sl, m_pl, sm_sw, m_pw)  (Iris-versicolor)            0.166667   \n",
       "\n",
       "     consequent support   support  confidence      lift  leverage  conviction  \n",
       "114            0.333333  0.333333    0.819672  2.459016  0.197778    3.696970  \n",
       "358            0.333333  0.246667    0.822222  2.466667  0.146667    3.750000  \n",
       "372            0.333333  0.146667    0.846154  2.538462  0.088889    4.333333  \n",
       "384            0.333333  0.180000    0.843750  2.531250  0.108889    4.266667  \n",
       "398            0.333333  0.100000    0.833333  2.500000  0.060000    4.000000  \n",
       "436            0.333333  0.140000    0.807692  2.423077  0.082222    3.466667  \n",
       "578            0.333333  0.100000    0.833333  2.500000  0.060000    4.000000  \n",
       "607            0.333333  0.140000    0.840000  2.520000  0.084444    4.166667  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[ (rules['lift'] >= 1) &\n",
    "       (rules['confidence'] >= 0.8) & (rules['consequents']=={'Iris-versicolor'})]\n",
    "# most of the rows below contain as antecedents petal attributes\n",
    "# we can see that Iris-versicolors are often recognized by their\n",
    "# medium sized petals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(lg_sw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(sm_pl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(sm_pw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.182222</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>2.634146</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>5.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>(sm_pl, lg_sw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>(sm_pw, lg_sw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>(lg_sw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.071111</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>(sm_pl, m_sw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(m_sw, sm_pw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(m_sw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.084444</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(sm_pl, sm_pw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.168889</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>(sm_pl, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>(sm_pw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.206667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.137778</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>(sm_pl, sm_pw, lg_sw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.084444</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>(sm_pl, m_sw, sm_pw)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>(sm_pl, m_sw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>(m_sw, sm_pw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>(sm_pl, sm_pw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>(sm_pl, m_sw, sm_pw, sm_sl)</td>\n",
       "      <td>(Iris-setosa)</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     antecedents    consequents  antecedent support  \\\n",
       "1                        (lg_sw)  (Iris-setosa)            0.240000   \n",
       "2                        (sm_pl)  (Iris-setosa)            0.293333   \n",
       "5                        (sm_pw)  (Iris-setosa)            0.273333   \n",
       "7                        (sm_sl)  (Iris-setosa)            0.273333   \n",
       "65                (sm_pl, lg_sw)  (Iris-setosa)            0.166667   \n",
       "72                (sm_pw, lg_sw)  (Iris-setosa)            0.146667   \n",
       "78                (lg_sw, sm_sl)  (Iris-setosa)            0.106667   \n",
       "82                 (sm_pl, m_sw)  (Iris-setosa)            0.120000   \n",
       "87                 (m_sw, sm_pw)  (Iris-setosa)            0.120000   \n",
       "91                 (m_sw, sm_sl)  (Iris-setosa)            0.126667   \n",
       "97                (sm_pl, sm_pw)  (Iris-setosa)            0.253333   \n",
       "103               (sm_pl, sm_sl)  (Iris-setosa)            0.220000   \n",
       "110               (sm_pw, sm_sl)  (Iris-setosa)            0.206667   \n",
       "290        (sm_pl, sm_pw, lg_sw)  (Iris-setosa)            0.126667   \n",
       "303         (sm_pl, m_sw, sm_pw)  (Iris-setosa)            0.120000   \n",
       "317         (sm_pl, m_sw, sm_sl)  (Iris-setosa)            0.120000   \n",
       "332         (m_sw, sm_pw, sm_sl)  (Iris-setosa)            0.120000   \n",
       "346        (sm_pl, sm_pw, sm_sl)  (Iris-setosa)            0.200000   \n",
       "548  (sm_pl, m_sw, sm_pw, sm_sl)  (Iris-setosa)            0.120000   \n",
       "\n",
       "     consequent support   support  confidence      lift  leverage  conviction  \n",
       "1              0.333333  0.200000    0.833333  2.500000  0.120000    4.000000  \n",
       "2              0.333333  0.293333    1.000000  3.000000  0.195556         inf  \n",
       "5              0.333333  0.273333    1.000000  3.000000  0.182222         inf  \n",
       "7              0.333333  0.240000    0.878049  2.634146  0.148889    5.466667  \n",
       "65             0.333333  0.166667    1.000000  3.000000  0.111111         inf  \n",
       "72             0.333333  0.146667    1.000000  3.000000  0.097778         inf  \n",
       "78             0.333333  0.106667    1.000000  3.000000  0.071111         inf  \n",
       "82             0.333333  0.120000    1.000000  3.000000  0.080000         inf  \n",
       "87             0.333333  0.120000    1.000000  3.000000  0.080000         inf  \n",
       "91             0.333333  0.126667    1.000000  3.000000  0.084444         inf  \n",
       "97             0.333333  0.253333    1.000000  3.000000  0.168889         inf  \n",
       "103            0.333333  0.220000    1.000000  3.000000  0.146667         inf  \n",
       "110            0.333333  0.206667    1.000000  3.000000  0.137778         inf  \n",
       "290            0.333333  0.126667    1.000000  3.000000  0.084444         inf  \n",
       "303            0.333333  0.120000    1.000000  3.000000  0.080000         inf  \n",
       "317            0.333333  0.120000    1.000000  3.000000  0.080000         inf  \n",
       "332            0.333333  0.120000    1.000000  3.000000  0.080000         inf  \n",
       "346            0.333333  0.200000    1.000000  3.000000  0.133333         inf  \n",
       "548            0.333333  0.120000    1.000000  3.000000  0.080000         inf  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[(rules['consequents']=={'Iris-setosa'})]\n",
    "# row 3,5 and 98 have the highest antecedent support & confidence, which shows\n",
    "# that petal length and petal width are highly discriminant attributes\n",
    "# an Iris-setosa is often recognized by it's small and thin petals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.151111</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(lg_pw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.151111</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(lg_sl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>2.228571</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>2.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(m_sw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>1.164179</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>1.089431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(sm_sw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>1.212766</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>(lg_pw, lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>(lg_sl, lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>(m_sw, lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>(lg_sl, lg_pw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>(m_sw, lg_pw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.075556</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>(lg_sl, m_sw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>2.192308</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>2.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>(lg_sl, lg_pw, lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.084444</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>(m_sw, lg_pw, lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>(lg_sl, m_sw, lg_pl)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.075556</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>(lg_sl, m_sw, lg_pw)</td>\n",
       "      <td>(Iris-virginica)</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               antecedents       consequents  antecedent support  \\\n",
       "17                 (lg_pl)  (Iris-virginica)            0.226667   \n",
       "19                 (lg_pw)  (Iris-virginica)            0.226667   \n",
       "20                 (lg_sl)  (Iris-virginica)            0.233333   \n",
       "23                  (m_sw)  (Iris-virginica)            0.446667   \n",
       "25                 (sm_sw)  (Iris-virginica)            0.313333   \n",
       "164         (lg_pw, lg_pl)  (Iris-virginica)            0.173333   \n",
       "169         (lg_sl, lg_pl)  (Iris-virginica)            0.160000   \n",
       "176          (m_sw, lg_pl)  (Iris-virginica)            0.140000   \n",
       "181         (lg_sl, lg_pw)  (Iris-virginica)            0.140000   \n",
       "188          (m_sw, lg_pw)  (Iris-virginica)            0.113333   \n",
       "193          (lg_sl, m_sw)  (Iris-virginica)            0.173333   \n",
       "452  (lg_sl, lg_pw, lg_pl)  (Iris-virginica)            0.126667   \n",
       "467   (m_sw, lg_pw, lg_pl)  (Iris-virginica)            0.100000   \n",
       "480   (lg_sl, m_sw, lg_pl)  (Iris-virginica)            0.113333   \n",
       "494   (lg_sl, m_sw, lg_pw)  (Iris-virginica)            0.100000   \n",
       "\n",
       "     consequent support   support  confidence      lift  leverage  conviction  \n",
       "17             0.333333  0.226667    1.000000  3.000000  0.151111         inf  \n",
       "19             0.333333  0.226667    1.000000  3.000000  0.151111         inf  \n",
       "20             0.333333  0.173333    0.742857  2.228571  0.095556    2.592593  \n",
       "23             0.333333  0.173333    0.388060  1.164179  0.024444    1.089431  \n",
       "25             0.333333  0.126667    0.404255  1.212766  0.022222    1.119048  \n",
       "164            0.333333  0.173333    1.000000  3.000000  0.115556         inf  \n",
       "169            0.333333  0.160000    1.000000  3.000000  0.106667         inf  \n",
       "176            0.333333  0.140000    1.000000  3.000000  0.093333         inf  \n",
       "181            0.333333  0.140000    1.000000  3.000000  0.093333         inf  \n",
       "188            0.333333  0.113333    1.000000  3.000000  0.075556         inf  \n",
       "193            0.333333  0.126667    0.730769  2.192308  0.068889    2.476190  \n",
       "452            0.333333  0.126667    1.000000  3.000000  0.084444         inf  \n",
       "467            0.333333  0.100000    1.000000  3.000000  0.066667         inf  \n",
       "480            0.333333  0.113333    1.000000  3.000000  0.075556         inf  \n",
       "494            0.333333  0.100000    1.000000  3.000000  0.066667         inf  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[(rules['consequents']=={'Iris-virginica'})]\n",
    "# Again here and for the same reasons above we can understand that\n",
    "# Iris-virginicas are often recognized by their long and large petals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These associations results correspond perfectly with what we've observed on weka\n",
    "# (see ./iris-vizualisation.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
